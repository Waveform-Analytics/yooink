{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#yooink-documentation","title":"Yooink Documentation","text":""},{"location":"#welcome","title":"Welcome!","text":"<p>Thanks for checking out the yooink Python package. You can use  it to access OOI (Ocean Observatories Initiative)  data, specifically the OOI data that is accessible via the M2M  (Machine-to-machine) interface. </p> <p>yooink essentially provides a wrapper around the existing API to make data  query and access a bit simpler. It abstracts away some of the things you  may not want to code up manually every time - so you can get the data you  want more efficiently!</p>"},{"location":"#installation","title":"Installation","text":"<p>You can install this package from PyPI using:</p> <pre><code>pip install yooink\n</code></pre>"},{"location":"#examples","title":"Examples","text":"<p>In the repository for this  project, you'll find a folder called \"notebooks\" with a collection of  Jupyter notebooks that walk users through some steps to get started using  yooink.</p>"},{"location":"#credits-references","title":"Credits / References","text":"<p>A lot of what's \"under the hood\", so to speak, is gleaned from either the  OOI API cheat sheet or from this Jupyter notebook  that walks through an example set-up for accessing data using Python. </p> <p>The OOI github organization also hosts this awesome Python toolset if you  need something more sophisticated, although it does require a bit more work  to get up and running (you'll need to clone it and run locally in  development mode).</p>"},{"location":"#code","title":"Code","text":"<p>You can find the Github repository here.</p>"},{"location":"about/","title":"About","text":"<p>This open source project was created by Michelle Weirathmueller at Waveform  Analytics, LLC.</p> <p>If you find any issues, please report them on the issues page. We'd  love it  if you could include as much detail as possible, including any steps to  reproduce the problem. Thank you!</p> <p>If you have any questions, or if you'd like to contribute to this package,  please contact info@waveformanalytics.com.</p> <p></p>"},{"location":"api/api/","title":"OOI API Handling Module","text":""},{"location":"api/api/#yooink.api.client.APIClient","title":"<code>APIClient</code>","text":"Source code in <code>yooink/api/client.py</code> <pre><code>class APIClient:\n    # Set Up Constants:\n    # Base URL for accessing OOI data\n    BASE_URL = 'https://ooinet.oceanobservatories.org/api/m2m/'\n    # different M2M interfaces to the base URL\n    ANNO_URL = '12580/anno/'  # Annotation Information\n    ASSET_URL = '12587/asset/'  # Asset and Calibration Information\n    DEPLOY_URL = '12587/events/deployment/inv/'  # Deployment Information\n    SENSOR_URL = '12576/sensor/inv/'  # Sensor Information\n    VOCAB_URL = '12586/vocab/inv/'  # Vocabulary Information\n    STREAM_URL = '12575/stream/byname/'  # Stream Information\n    PARAMETER_URL = '12575/parameter/'  # Parameter Information\n\n    def __init__(self, username: str, token: str) -&gt; None:\n        \"\"\"\n        Initializes the APIClient with base URL, API username, and token for\n        authentication.\n\n        Args:\n=           username: The API username.\n            token: The API authentication token.\n        \"\"\"\n        self.auth = (username, token)\n        self.session = requests.Session()\n\n    @staticmethod\n    def get_headers() -&gt; Dict[str, str]:\n        \"\"\"\n        Returns headers for the API request.\n\n        Returns:\n            A dictionary containing headers.\n        \"\"\"\n        return {'Content-Type': 'application/json'}\n\n    def make_request(\n            self,\n            interface: M2MInterface,\n            endpoint: str,\n            params: Optional[Dict[str, Any]] = None\n    ) -&gt; Any:\n        \"\"\"\n        Sends a GET request to the API, with optional parameters.\n\n        Args:\n            interface: The M2M interface to use (from M2MInterface Enum).\n            endpoint: The API endpoint to request.\n            params: Optional query parameters for the request.\n\n        Returns:\n            The parsed JSON response.\n        \"\"\"\n        url = self.construct_url(interface, endpoint)\n        response = self.session.get(\n            url, auth=self.auth, headers=self.get_headers(), params=params)\n        response.raise_for_status()\n        return response.json()\n\n    def construct_url(self, interface: M2MInterface, endpoint: str) -&gt; str:\n        \"\"\"\n        Constructs the full URL for the API request based on the interface and endpoint.\n\n        Args:\n            interface: The M2M interface to use (from M2MInterface Enum).\n            endpoint: The specific endpoint to append to the interface.\n\n        Returns:\n            The full URL.\n        \"\"\"\n        return f\"{self.BASE_URL}{interface.value}{endpoint}\"\n\n    def fetch_thredds_page(self, thredds_url: str) -&gt; str:\n        \"\"\"\n        Sends a GET request to the THREDDS server. Uses the session's\n        built-in retry mechanism for handling delays in data availability.\n\n        Args:\n            thredds_url: The full URL to the THREDDS server.\n\n        Returns:\n            The HTML content of the page.\n\n        Raises:\n            Exception: If the data is still unavailable after all retries.\n        \"\"\"\n        response = self.session.get(thredds_url)\n        response.raise_for_status()\n        return response.text\n</code></pre>"},{"location":"api/api/#yooink.api.client.APIClient.__init__","title":"<code>__init__(username, token)</code>","text":"<pre><code>    Initializes the APIClient with base URL, API username, and token for\n    authentication.\n\n    Args:\n</code></pre> <p>=           username: The API username.             token: The API authentication token.</p> Source code in <code>yooink/api/client.py</code> <pre><code>    def __init__(self, username: str, token: str) -&gt; None:\n        \"\"\"\n        Initializes the APIClient with base URL, API username, and token for\n        authentication.\n\n        Args:\n=           username: The API username.\n            token: The API authentication token.\n        \"\"\"\n        self.auth = (username, token)\n        self.session = requests.Session()\n</code></pre>"},{"location":"api/api/#yooink.api.client.APIClient.construct_url","title":"<code>construct_url(interface, endpoint)</code>","text":"<p>Constructs the full URL for the API request based on the interface and endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>interface</code> <code>M2MInterface</code> <p>The M2M interface to use (from M2MInterface Enum).</p> required <code>endpoint</code> <code>str</code> <p>The specific endpoint to append to the interface.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The full URL.</p> Source code in <code>yooink/api/client.py</code> <pre><code>def construct_url(self, interface: M2MInterface, endpoint: str) -&gt; str:\n    \"\"\"\n    Constructs the full URL for the API request based on the interface and endpoint.\n\n    Args:\n        interface: The M2M interface to use (from M2MInterface Enum).\n        endpoint: The specific endpoint to append to the interface.\n\n    Returns:\n        The full URL.\n    \"\"\"\n    return f\"{self.BASE_URL}{interface.value}{endpoint}\"\n</code></pre>"},{"location":"api/api/#yooink.api.client.APIClient.fetch_thredds_page","title":"<code>fetch_thredds_page(thredds_url)</code>","text":"<p>Sends a GET request to the THREDDS server. Uses the session's built-in retry mechanism for handling delays in data availability.</p> <p>Parameters:</p> Name Type Description Default <code>thredds_url</code> <code>str</code> <p>The full URL to the THREDDS server.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The HTML content of the page.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the data is still unavailable after all retries.</p> Source code in <code>yooink/api/client.py</code> <pre><code>def fetch_thredds_page(self, thredds_url: str) -&gt; str:\n    \"\"\"\n    Sends a GET request to the THREDDS server. Uses the session's\n    built-in retry mechanism for handling delays in data availability.\n\n    Args:\n        thredds_url: The full URL to the THREDDS server.\n\n    Returns:\n        The HTML content of the page.\n\n    Raises:\n        Exception: If the data is still unavailable after all retries.\n    \"\"\"\n    response = self.session.get(thredds_url)\n    response.raise_for_status()\n    return response.text\n</code></pre>"},{"location":"api/api/#yooink.api.client.APIClient.get_headers","title":"<code>get_headers()</code>  <code>staticmethod</code>","text":"<p>Returns headers for the API request.</p> <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>A dictionary containing headers.</p> Source code in <code>yooink/api/client.py</code> <pre><code>@staticmethod\ndef get_headers() -&gt; Dict[str, str]:\n    \"\"\"\n    Returns headers for the API request.\n\n    Returns:\n        A dictionary containing headers.\n    \"\"\"\n    return {'Content-Type': 'application/json'}\n</code></pre>"},{"location":"api/api/#yooink.api.client.APIClient.make_request","title":"<code>make_request(interface, endpoint, params=None)</code>","text":"<p>Sends a GET request to the API, with optional parameters.</p> <p>Parameters:</p> Name Type Description Default <code>interface</code> <code>M2MInterface</code> <p>The M2M interface to use (from M2MInterface Enum).</p> required <code>endpoint</code> <code>str</code> <p>The API endpoint to request.</p> required <code>params</code> <code>Optional[Dict[str, Any]]</code> <p>Optional query parameters for the request.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The parsed JSON response.</p> Source code in <code>yooink/api/client.py</code> <pre><code>def make_request(\n        self,\n        interface: M2MInterface,\n        endpoint: str,\n        params: Optional[Dict[str, Any]] = None\n) -&gt; Any:\n    \"\"\"\n    Sends a GET request to the API, with optional parameters.\n\n    Args:\n        interface: The M2M interface to use (from M2MInterface Enum).\n        endpoint: The API endpoint to request.\n        params: Optional query parameters for the request.\n\n    Returns:\n        The parsed JSON response.\n    \"\"\"\n    url = self.construct_url(interface, endpoint)\n    response = self.session.get(\n        url, auth=self.auth, headers=self.get_headers(), params=params)\n    response.raise_for_status()\n    return response.json()\n</code></pre>"},{"location":"api/data_fetcher/","title":"Data Fetcher Module","text":""},{"location":"api/data_fetcher/#yooink.request.data_fetcher.DataFetcher","title":"<code>DataFetcher</code>","text":"Source code in <code>yooink/request/data_fetcher.py</code> <pre><code>class DataFetcher:\n    def __init__(self, username=None, token=None) -&gt; None:\n        \"\"\" Initialize the DatasetFetcher. \"\"\"\n        self.username = username or os.getenv('OOI_USER')\n        self.token = token or os.getenv('OOI_TOKEN')\n        self.api_client = APIClient(self.username, self.token)\n        self.data_manager = DataManager()\n        self.request_manager = RequestManager(\n            self.api_client, use_file_cache=True)\n\n    @staticmethod\n    def filter_urls(\n            site: str,\n            assembly: str,\n            instrument: str,\n            method: str\n    ) -&gt; tuple[List[str], List[str], List[str]]:\n        \"\"\"\n        Filters the M2M_URLS dictionary for the instrument of interest.\n\n        This function searches for the instrument of interest as defined by the\n        site code, assembly type, instrument class, and data delivery method to\n        return the OOI specific site, node and stream names needed to\n        request the data.\n\n        Args:\n            site: OOI eight letter site code (e.g. CE04OSPS for the Oregon\n                Offshore Shallow Profiler)\n            assembly: Assembly grouping name (e.g. midwater for the 200 m\n                Platform)\n            instrument: The instrument class name (e.g. phsen for the\n                SAMI2-pH sensor)\n            method: The data delivery method (e.g. streamed for cabled\n                streaming data)\n\n        Returns:\n            A tuple containing three lists:\n                - node: The OOI specific node code(s) for the assembly\n                - sensor: The OOI specific sensor code(s) for the instrument\n                    class\n                - stream: The OOI specific stream name(s) for the site, node,\n                    sensor and delivery method combination\n\n        Raises:\n            SyntaxError: If an unknown site code or data delivery method is\n                provided.\n            RuntimeWarning: If the instrument defined by the given parameters\n                cannot be found.\n        \"\"\"\n        node: List[str] = []\n        sensor: List[str] = []\n        stream: List[str] = []\n\n        # Pare the larger dictionary down to the site of interest and check if\n        # a valid site was used\n        m2m_urls: Dict[str, Any] = M2M_URLS.get(site.upper())\n        if not m2m_urls:\n            raise SyntaxError(f'Unknown site code: {site}')\n\n        # Make sure the correct data delivery method was specified\n        valid_methods = ['streamed', 'telemetered', 'recovered_host',\n                         'recovered_inst', 'recovered_cspp', 'recovered_wfp']\n        if method not in valid_methods:\n            raise SyntaxError(f'Unknown data delivery method: {method}')\n\n        # Find the instrument(s) of interest in the assembly group\n        for grouping in m2m_urls.get('assembly', []):\n            if grouping.get('type') == assembly or grouping.get(\n                    'subassembly') == assembly:\n                for instrmt in grouping['instrument']:\n                    if instrmt['class'] == instrument:\n                        node.append(instrmt.node)\n                        sensor.append(instrmt.sensor)\n                        stream.append(instrmt.stream.get(method))\n\n        # Check to see if we were able to find the system of interest\n        if not stream:\n            raise RuntimeWarning(\n                f'Instrument defined by {site}-{assembly}-{instrument}-'\n                f'{method} cannot be found.')\n\n        # Return the OOI specific names for the node(s), sensor(s) and\n        # stream(s)\n        return node, sensor, stream\n\n    def get_dataset(\n            self,\n            site: str,\n            assembly: str,\n            instrument: str,\n            method: str,\n            **kwargs: Any\n    ) -&gt; xr.Dataset:\n        \"\"\"\n        Requests data via the OOI M2M API using the site code, assembly type,\n        instrument class and data delivery method.\n\n        This function constructs the OOI specific data request using the\n        parameters defined in the m2m_urls.yml file.\n\n        Args:\n            site: OOI site code as an 8 character string\n            assembly: The assembly type where the instrument is located\n            instrument: The OOI instrument class name for the instrument of\n                interest\n            method: The data delivery method for the system of interest\n            **kwargs: Optional keyword arguments:\n                start: Starting date/time for the data request in a\n                    dateutil.parser recognizable form. If None, the beginning\n                    of the data record will be used.\n                stop: Ending date/time for the data request in a\n                    dateutil.parser recognizable form. If None, the end of\n                    the data record will be used.\n                deploy: Use the deployment number (integer) to set the starting\n                    and ending dates. If None, the starting and ending dates\n                    are used. If both are provided, the deployment number\n                    takes priority.\n                aggregate: In cases where more than one instance of an\n                    instrument class is part of an assembly, will collect\n                    all the data if 0, or the specific instance of the\n                    instrument if any value greater than 0 is used. If None,\n                    the first instance of an instrument will be used.\n\n        Returns:\n            An xarray dataset containing the requested data for further\n            analysis.\n\n        Raises:\n            KeyError: If an unknown keyword argument is provided.\n            SyntaxError: If the date string format is unrecognizable or if an\n                invalid aggregate value is provided.\n            RuntimeWarning: If deployment dates are unavailable or if data is\n                unavailable for the specified parameters.\n        \"\"\"\n        # Setup inputs to the function, make sure case is correct\n        site = site.upper()\n        assembly = assembly.lower()\n        instrument = instrument.lower()\n        method = method.lower()\n\n        # Parse the keyword arguments\n        start: Optional[str] = None\n        stop: Optional[str] = None\n        deploy: Optional[int] = None\n        aggregate: Optional[int] = None\n        for key, value in kwargs.items():\n            if key not in ['start', 'stop', 'deploy', 'aggregate']:\n                raise KeyError(f'Unknown keyword ({key}) argument.')\n            else:\n                if key == 'start':\n                    start = value\n                if key == 'stop':\n                    stop = value\n                if key == 'deploy':\n                    deploy = value\n                if key == 'aggregate':\n                    aggregate = value\n\n        # Use the assembly, instrument and data delivery methods to find the\n        # system of interest\n        node, sensor, stream = self.filter_urls(\n            site, assembly, instrument, method)\n\n        # Check the formatting of the start and end dates. We need to be able\n        # to parse and convert to an ISO format.\n        if start:\n            try:\n                start = parser.parse(start)\n                start = start.astimezone(pytz.utc)\n                start = start.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n            except parser.ParserError:\n                raise SyntaxError(\n                    'Formatting of the starting date string needs to be in a '\n                    'recognizable format')\n\n        if stop:\n            try:\n                stop = parser.parse(stop)\n                stop = stop.astimezone(pytz.utc)\n                stop = stop.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n            except parser.ParserError:\n                raise SyntaxError(\n                    'Formatting of the ending date string needs to be in a '\n                    'recognizable format')\n\n        if deploy:\n            # Determine start and end dates based on the deployment number\n            start, stop = self.request_manager.get_deployment_dates(\n                site, node[0], sensor[0], deploy)\n            if not start or not stop:\n                exit_text = (\n                    f'Deployment dates are unavailable for {site.lower()}-'\n                    f'{assembly}-{instrument}-{method}, '\n                    f'deployment {deploy:02d}.')\n                raise RuntimeWarning(exit_text)\n\n        # For some cases, there may be more than 1 stream, but in general,\n        # we only want the first one\n        stream = stream[0][0] if isinstance(stream[0], list) else stream[0]\n\n        tag = f'.*{instrument.upper()}.*\\\\.nc$'  # set regex tag\n        data: Optional[xr.Dataset] = None  # setup the default data set\n\n        # Check if there are multiple instances of this instrument class on the\n        # assembly\n        if len(node) &gt; 1:\n            print(\n                f'There are multiple instances of the instrument {instrument} '\n                f'under {site.lower()}-{assembly}.')\n\n        # Check if we are aggregating the multiple instruments into a single\n        # data set\n        if isinstance(aggregate, int):\n            if aggregate == 0:\n                print(\n                    f'Requesting all {len(node)} instances of this '\n                    f'instrument. Data sets will be concatenated\\n'\n                    'and a new variable called `sensor_count` will be added '\n                    'to help distinguish the \\n'\n                    'instruments for later processing.')\n                for i in range(len(node)):\n                    temp = self.request_manager.fetch_data(\n                        site, node[i], sensor[i], method, stream, start, stop,\n                        tag=tag\n                    )\n                    temp['sensor_count'] = temp['deployment'] * 0 + i + 1\n                    if not data:\n                        data = temp\n                    else:\n                        data = xr.concat([data, temp], dim='time')\n            else:\n                if aggregate &gt; len(node):\n                    raise SyntaxError(\n                        f'Only {len(node)} instruments available, you '\n                        f'selected {aggregate}')\n\n                print(f'Requesting instrument {aggregate} out of {len(node)}.')\n                i = aggregate - 1\n                data = self.request_manager.fetch_data(\n                    site, node[i], sensor[i], method, stream, start, stop,\n                    tag=tag\n                )\n\n        else:\n            data = self.request_manager.fetch_data(\n                site, node[0], sensor[0], method, stream, start, stop,\n                tag=tag\n            )\n\n        if not data:\n            raise RuntimeWarning(\n                f'Data unavailable for {site.lower()}-{assembly}-'\n                f'{instrument}-{method}.')\n\n        # Convert strings with data types set as objects or S64 with binary\n        # encoding\n        for v in data.variables:\n            if data[v].dtype == np.dtype('O') or data[v].dtype == np.dtype(\n                    'S64'):\n                data[v] = data[v].astype(np.str_)\n\n        return data\n</code></pre>"},{"location":"api/data_fetcher/#yooink.request.data_fetcher.DataFetcher.__init__","title":"<code>__init__(username=None, token=None)</code>","text":"<p>Initialize the DatasetFetcher.</p> Source code in <code>yooink/request/data_fetcher.py</code> <pre><code>def __init__(self, username=None, token=None) -&gt; None:\n    \"\"\" Initialize the DatasetFetcher. \"\"\"\n    self.username = username or os.getenv('OOI_USER')\n    self.token = token or os.getenv('OOI_TOKEN')\n    self.api_client = APIClient(self.username, self.token)\n    self.data_manager = DataManager()\n    self.request_manager = RequestManager(\n        self.api_client, use_file_cache=True)\n</code></pre>"},{"location":"api/data_fetcher/#yooink.request.data_fetcher.DataFetcher.filter_urls","title":"<code>filter_urls(site, assembly, instrument, method)</code>  <code>staticmethod</code>","text":"<p>Filters the M2M_URLS dictionary for the instrument of interest.</p> <p>This function searches for the instrument of interest as defined by the site code, assembly type, instrument class, and data delivery method to return the OOI specific site, node and stream names needed to request the data.</p> <p>Parameters:</p> Name Type Description Default <code>site</code> <code>str</code> <p>OOI eight letter site code (e.g. CE04OSPS for the Oregon Offshore Shallow Profiler)</p> required <code>assembly</code> <code>str</code> <p>Assembly grouping name (e.g. midwater for the 200 m Platform)</p> required <code>instrument</code> <code>str</code> <p>The instrument class name (e.g. phsen for the SAMI2-pH sensor)</p> required <code>method</code> <code>str</code> <p>The data delivery method (e.g. streamed for cabled streaming data)</p> required <p>Returns:</p> Type Description <code>tuple[List[str], List[str], List[str]]</code> <p>A tuple containing three lists: - node: The OOI specific node code(s) for the assembly - sensor: The OOI specific sensor code(s) for the instrument     class - stream: The OOI specific stream name(s) for the site, node,     sensor and delivery method combination</p> <p>Raises:</p> Type Description <code>SyntaxError</code> <p>If an unknown site code or data delivery method is provided.</p> <code>RuntimeWarning</code> <p>If the instrument defined by the given parameters cannot be found.</p> Source code in <code>yooink/request/data_fetcher.py</code> <pre><code>@staticmethod\ndef filter_urls(\n        site: str,\n        assembly: str,\n        instrument: str,\n        method: str\n) -&gt; tuple[List[str], List[str], List[str]]:\n    \"\"\"\n    Filters the M2M_URLS dictionary for the instrument of interest.\n\n    This function searches for the instrument of interest as defined by the\n    site code, assembly type, instrument class, and data delivery method to\n    return the OOI specific site, node and stream names needed to\n    request the data.\n\n    Args:\n        site: OOI eight letter site code (e.g. CE04OSPS for the Oregon\n            Offshore Shallow Profiler)\n        assembly: Assembly grouping name (e.g. midwater for the 200 m\n            Platform)\n        instrument: The instrument class name (e.g. phsen for the\n            SAMI2-pH sensor)\n        method: The data delivery method (e.g. streamed for cabled\n            streaming data)\n\n    Returns:\n        A tuple containing three lists:\n            - node: The OOI specific node code(s) for the assembly\n            - sensor: The OOI specific sensor code(s) for the instrument\n                class\n            - stream: The OOI specific stream name(s) for the site, node,\n                sensor and delivery method combination\n\n    Raises:\n        SyntaxError: If an unknown site code or data delivery method is\n            provided.\n        RuntimeWarning: If the instrument defined by the given parameters\n            cannot be found.\n    \"\"\"\n    node: List[str] = []\n    sensor: List[str] = []\n    stream: List[str] = []\n\n    # Pare the larger dictionary down to the site of interest and check if\n    # a valid site was used\n    m2m_urls: Dict[str, Any] = M2M_URLS.get(site.upper())\n    if not m2m_urls:\n        raise SyntaxError(f'Unknown site code: {site}')\n\n    # Make sure the correct data delivery method was specified\n    valid_methods = ['streamed', 'telemetered', 'recovered_host',\n                     'recovered_inst', 'recovered_cspp', 'recovered_wfp']\n    if method not in valid_methods:\n        raise SyntaxError(f'Unknown data delivery method: {method}')\n\n    # Find the instrument(s) of interest in the assembly group\n    for grouping in m2m_urls.get('assembly', []):\n        if grouping.get('type') == assembly or grouping.get(\n                'subassembly') == assembly:\n            for instrmt in grouping['instrument']:\n                if instrmt['class'] == instrument:\n                    node.append(instrmt.node)\n                    sensor.append(instrmt.sensor)\n                    stream.append(instrmt.stream.get(method))\n\n    # Check to see if we were able to find the system of interest\n    if not stream:\n        raise RuntimeWarning(\n            f'Instrument defined by {site}-{assembly}-{instrument}-'\n            f'{method} cannot be found.')\n\n    # Return the OOI specific names for the node(s), sensor(s) and\n    # stream(s)\n    return node, sensor, stream\n</code></pre>"},{"location":"api/data_fetcher/#yooink.request.data_fetcher.DataFetcher.get_dataset","title":"<code>get_dataset(site, assembly, instrument, method, **kwargs)</code>","text":"<p>Requests data via the OOI M2M API using the site code, assembly type, instrument class and data delivery method.</p> <p>This function constructs the OOI specific data request using the parameters defined in the m2m_urls.yml file.</p> <p>Parameters:</p> Name Type Description Default <code>site</code> <code>str</code> <p>OOI site code as an 8 character string</p> required <code>assembly</code> <code>str</code> <p>The assembly type where the instrument is located</p> required <code>instrument</code> <code>str</code> <p>The OOI instrument class name for the instrument of interest</p> required <code>method</code> <code>str</code> <p>The data delivery method for the system of interest</p> required <code>**kwargs</code> <code>Any</code> <p>Optional keyword arguments: start: Starting date/time for the data request in a     dateutil.parser recognizable form. If None, the beginning     of the data record will be used. stop: Ending date/time for the data request in a     dateutil.parser recognizable form. If None, the end of     the data record will be used. deploy: Use the deployment number (integer) to set the starting     and ending dates. If None, the starting and ending dates     are used. If both are provided, the deployment number     takes priority. aggregate: In cases where more than one instance of an     instrument class is part of an assembly, will collect     all the data if 0, or the specific instance of the     instrument if any value greater than 0 is used. If None,     the first instance of an instrument will be used.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>An xarray dataset containing the requested data for further</p> <code>Dataset</code> <p>analysis.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If an unknown keyword argument is provided.</p> <code>SyntaxError</code> <p>If the date string format is unrecognizable or if an invalid aggregate value is provided.</p> <code>RuntimeWarning</code> <p>If deployment dates are unavailable or if data is unavailable for the specified parameters.</p> Source code in <code>yooink/request/data_fetcher.py</code> <pre><code>def get_dataset(\n        self,\n        site: str,\n        assembly: str,\n        instrument: str,\n        method: str,\n        **kwargs: Any\n) -&gt; xr.Dataset:\n    \"\"\"\n    Requests data via the OOI M2M API using the site code, assembly type,\n    instrument class and data delivery method.\n\n    This function constructs the OOI specific data request using the\n    parameters defined in the m2m_urls.yml file.\n\n    Args:\n        site: OOI site code as an 8 character string\n        assembly: The assembly type where the instrument is located\n        instrument: The OOI instrument class name for the instrument of\n            interest\n        method: The data delivery method for the system of interest\n        **kwargs: Optional keyword arguments:\n            start: Starting date/time for the data request in a\n                dateutil.parser recognizable form. If None, the beginning\n                of the data record will be used.\n            stop: Ending date/time for the data request in a\n                dateutil.parser recognizable form. If None, the end of\n                the data record will be used.\n            deploy: Use the deployment number (integer) to set the starting\n                and ending dates. If None, the starting and ending dates\n                are used. If both are provided, the deployment number\n                takes priority.\n            aggregate: In cases where more than one instance of an\n                instrument class is part of an assembly, will collect\n                all the data if 0, or the specific instance of the\n                instrument if any value greater than 0 is used. If None,\n                the first instance of an instrument will be used.\n\n    Returns:\n        An xarray dataset containing the requested data for further\n        analysis.\n\n    Raises:\n        KeyError: If an unknown keyword argument is provided.\n        SyntaxError: If the date string format is unrecognizable or if an\n            invalid aggregate value is provided.\n        RuntimeWarning: If deployment dates are unavailable or if data is\n            unavailable for the specified parameters.\n    \"\"\"\n    # Setup inputs to the function, make sure case is correct\n    site = site.upper()\n    assembly = assembly.lower()\n    instrument = instrument.lower()\n    method = method.lower()\n\n    # Parse the keyword arguments\n    start: Optional[str] = None\n    stop: Optional[str] = None\n    deploy: Optional[int] = None\n    aggregate: Optional[int] = None\n    for key, value in kwargs.items():\n        if key not in ['start', 'stop', 'deploy', 'aggregate']:\n            raise KeyError(f'Unknown keyword ({key}) argument.')\n        else:\n            if key == 'start':\n                start = value\n            if key == 'stop':\n                stop = value\n            if key == 'deploy':\n                deploy = value\n            if key == 'aggregate':\n                aggregate = value\n\n    # Use the assembly, instrument and data delivery methods to find the\n    # system of interest\n    node, sensor, stream = self.filter_urls(\n        site, assembly, instrument, method)\n\n    # Check the formatting of the start and end dates. We need to be able\n    # to parse and convert to an ISO format.\n    if start:\n        try:\n            start = parser.parse(start)\n            start = start.astimezone(pytz.utc)\n            start = start.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n        except parser.ParserError:\n            raise SyntaxError(\n                'Formatting of the starting date string needs to be in a '\n                'recognizable format')\n\n    if stop:\n        try:\n            stop = parser.parse(stop)\n            stop = stop.astimezone(pytz.utc)\n            stop = stop.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n        except parser.ParserError:\n            raise SyntaxError(\n                'Formatting of the ending date string needs to be in a '\n                'recognizable format')\n\n    if deploy:\n        # Determine start and end dates based on the deployment number\n        start, stop = self.request_manager.get_deployment_dates(\n            site, node[0], sensor[0], deploy)\n        if not start or not stop:\n            exit_text = (\n                f'Deployment dates are unavailable for {site.lower()}-'\n                f'{assembly}-{instrument}-{method}, '\n                f'deployment {deploy:02d}.')\n            raise RuntimeWarning(exit_text)\n\n    # For some cases, there may be more than 1 stream, but in general,\n    # we only want the first one\n    stream = stream[0][0] if isinstance(stream[0], list) else stream[0]\n\n    tag = f'.*{instrument.upper()}.*\\\\.nc$'  # set regex tag\n    data: Optional[xr.Dataset] = None  # setup the default data set\n\n    # Check if there are multiple instances of this instrument class on the\n    # assembly\n    if len(node) &gt; 1:\n        print(\n            f'There are multiple instances of the instrument {instrument} '\n            f'under {site.lower()}-{assembly}.')\n\n    # Check if we are aggregating the multiple instruments into a single\n    # data set\n    if isinstance(aggregate, int):\n        if aggregate == 0:\n            print(\n                f'Requesting all {len(node)} instances of this '\n                f'instrument. Data sets will be concatenated\\n'\n                'and a new variable called `sensor_count` will be added '\n                'to help distinguish the \\n'\n                'instruments for later processing.')\n            for i in range(len(node)):\n                temp = self.request_manager.fetch_data(\n                    site, node[i], sensor[i], method, stream, start, stop,\n                    tag=tag\n                )\n                temp['sensor_count'] = temp['deployment'] * 0 + i + 1\n                if not data:\n                    data = temp\n                else:\n                    data = xr.concat([data, temp], dim='time')\n        else:\n            if aggregate &gt; len(node):\n                raise SyntaxError(\n                    f'Only {len(node)} instruments available, you '\n                    f'selected {aggregate}')\n\n            print(f'Requesting instrument {aggregate} out of {len(node)}.')\n            i = aggregate - 1\n            data = self.request_manager.fetch_data(\n                site, node[i], sensor[i], method, stream, start, stop,\n                tag=tag\n            )\n\n    else:\n        data = self.request_manager.fetch_data(\n            site, node[0], sensor[0], method, stream, start, stop,\n            tag=tag\n        )\n\n    if not data:\n        raise RuntimeWarning(\n            f'Data unavailable for {site.lower()}-{assembly}-'\n            f'{instrument}-{method}.')\n\n    # Convert strings with data types set as objects or S64 with binary\n    # encoding\n    for v in data.variables:\n        if data[v].dtype == np.dtype('O') or data[v].dtype == np.dtype(\n                'S64'):\n            data[v] = data[v].astype(np.str_)\n\n    return data\n</code></pre>"},{"location":"api/data_manager/","title":"Data Manager Module","text":""},{"location":"api/data_manager/#yooink.data.data_manager.DataManager","title":"<code>DataManager</code>","text":"Source code in <code>yooink/data/data_manager.py</code> <pre><code>class DataManager:\n    def __init__(self) -&gt; None:\n        \"\"\"Initializes the DataManager.\"\"\"\n        pass\n\n    @staticmethod\n    def process_file(catalog_file: str, use_dask: bool = False\n                     ) -&gt; xr.Dataset | None:\n        \"\"\"\n        Download and process a NetCDF file into an xarray dataset.\n\n        Args:\n            catalog_file: URL or path to the NetCDF file.\n            use_dask: Whether to use dask for processing (for large files).\n\n        Returns:\n            The xarray dataset.\n        \"\"\"\n        try:\n            # Convert the catalog file URL to the data URL\n            tds_url = ('https://opendap.oceanobservatories.org/thredds/'\n                       'fileServer/')\n            data_url = re.sub(\n                r'catalog.html\\?dataset=', tds_url, catalog_file)\n\n            # Download the dataset\n            r = requests.get(data_url, timeout=(3.05, 120))\n            if not r.ok:\n                warnings.warn(f\"Failed to download {catalog_file}\")\n                return None\n\n            # Load the data into an xarray dataset\n            data = io.BytesIO(r.content)\n            if use_dask:\n                ds = xr.open_dataset(\n                    data, decode_cf=False, chunks='auto', mask_and_scale=False)\n            else:\n                ds = xr.load_dataset(\n                    data, decode_cf=False, mask_and_scale=False)\n\n            # Process the dataset\n            ds = ds.swap_dims({'obs': 'time'}).reset_coords()\n            ds = ds.sortby('time')\n\n            # Drop unnecessary variables, clean time units\n            keys_to_drop = ['obs', 'id', 'provenance', 'driver_timestamp',\n                            'ingestion_timestamp']\n            ds = ds.drop_vars([key for key in keys_to_drop\n                               if key in ds.variables])\n\n            return ds\n        except Exception as e:\n            warnings.warn(f\"Error processing {catalog_file}: {e}\")\n            return None\n\n    def merge_frames(self, frames: List[xr.Dataset]) -&gt; xr.Dataset:\n        \"\"\"\n        Merge multiple datasets into a single xarray dataset.\n\n        Args:\n            frames: A list of xarray datasets to merge.\n\n        Returns:\n            The merged xarray dataset.\n        \"\"\"\n        if len(frames) == 1:\n            return frames[0]\n\n        # Attempt to merge the datasets\n        try:\n            data = xr.concat(frames, dim='time')\n        except ValueError:\n            # If concatenation fails, attempt merging one by one\n            data, failed = self._frame_merger(frames[0], frames)\n            if failed &gt; 0:\n                warnings.warn(f\"{failed} frames failed to merge.\")\n\n        # Sort by time and remove duplicates\n        data = data.sortby('time')\n        _, index = np.unique(data['time'], return_index=True)\n        data = data.isel(time=index)\n\n        return data\n\n    @staticmethod\n    def _frame_merger(\n            data: xr.Dataset, frames: List[xr.Dataset]\n    ) -&gt; (xr.Dataset, int):\n        \"\"\"\n        Helper function to merge datasets one-by-one if bulk concatenation\n        fails.\n\n        Args:\n            data: The initial dataset to merge.\n            frames: The remaining datasets to merge into the initial one.\n\n        Returns:\n            The merged dataset and a count of failed merges.\n        \"\"\"\n        failed = 0\n        for frame in frames[1:]:\n            try:\n                data = xr.concat([data, frame], dim='time')\n            except (ValueError, NotImplementedError):\n                try:\n                    data = data.merge(frame, compat='override')\n                except (ValueError, NotImplementedError):\n                    failed += 1\n        return data, failed\n</code></pre>"},{"location":"api/data_manager/#yooink.data.data_manager.DataManager.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the DataManager.</p> Source code in <code>yooink/data/data_manager.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initializes the DataManager.\"\"\"\n    pass\n</code></pre>"},{"location":"api/data_manager/#yooink.data.data_manager.DataManager.merge_frames","title":"<code>merge_frames(frames)</code>","text":"<p>Merge multiple datasets into a single xarray dataset.</p> <p>Parameters:</p> Name Type Description Default <code>frames</code> <code>List[Dataset]</code> <p>A list of xarray datasets to merge.</p> required <p>Returns:</p> Type Description <code>Dataset</code> <p>The merged xarray dataset.</p> Source code in <code>yooink/data/data_manager.py</code> <pre><code>def merge_frames(self, frames: List[xr.Dataset]) -&gt; xr.Dataset:\n    \"\"\"\n    Merge multiple datasets into a single xarray dataset.\n\n    Args:\n        frames: A list of xarray datasets to merge.\n\n    Returns:\n        The merged xarray dataset.\n    \"\"\"\n    if len(frames) == 1:\n        return frames[0]\n\n    # Attempt to merge the datasets\n    try:\n        data = xr.concat(frames, dim='time')\n    except ValueError:\n        # If concatenation fails, attempt merging one by one\n        data, failed = self._frame_merger(frames[0], frames)\n        if failed &gt; 0:\n            warnings.warn(f\"{failed} frames failed to merge.\")\n\n    # Sort by time and remove duplicates\n    data = data.sortby('time')\n    _, index = np.unique(data['time'], return_index=True)\n    data = data.isel(time=index)\n\n    return data\n</code></pre>"},{"location":"api/data_manager/#yooink.data.data_manager.DataManager.process_file","title":"<code>process_file(catalog_file, use_dask=False)</code>  <code>staticmethod</code>","text":"<p>Download and process a NetCDF file into an xarray dataset.</p> <p>Parameters:</p> Name Type Description Default <code>catalog_file</code> <code>str</code> <p>URL or path to the NetCDF file.</p> required <code>use_dask</code> <code>bool</code> <p>Whether to use dask for processing (for large files).</p> <code>False</code> <p>Returns:</p> Type Description <code>Dataset | None</code> <p>The xarray dataset.</p> Source code in <code>yooink/data/data_manager.py</code> <pre><code>@staticmethod\ndef process_file(catalog_file: str, use_dask: bool = False\n                 ) -&gt; xr.Dataset | None:\n    \"\"\"\n    Download and process a NetCDF file into an xarray dataset.\n\n    Args:\n        catalog_file: URL or path to the NetCDF file.\n        use_dask: Whether to use dask for processing (for large files).\n\n    Returns:\n        The xarray dataset.\n    \"\"\"\n    try:\n        # Convert the catalog file URL to the data URL\n        tds_url = ('https://opendap.oceanobservatories.org/thredds/'\n                   'fileServer/')\n        data_url = re.sub(\n            r'catalog.html\\?dataset=', tds_url, catalog_file)\n\n        # Download the dataset\n        r = requests.get(data_url, timeout=(3.05, 120))\n        if not r.ok:\n            warnings.warn(f\"Failed to download {catalog_file}\")\n            return None\n\n        # Load the data into an xarray dataset\n        data = io.BytesIO(r.content)\n        if use_dask:\n            ds = xr.open_dataset(\n                data, decode_cf=False, chunks='auto', mask_and_scale=False)\n        else:\n            ds = xr.load_dataset(\n                data, decode_cf=False, mask_and_scale=False)\n\n        # Process the dataset\n        ds = ds.swap_dims({'obs': 'time'}).reset_coords()\n        ds = ds.sortby('time')\n\n        # Drop unnecessary variables, clean time units\n        keys_to_drop = ['obs', 'id', 'provenance', 'driver_timestamp',\n                        'ingestion_timestamp']\n        ds = ds.drop_vars([key for key in keys_to_drop\n                           if key in ds.variables])\n\n        return ds\n    except Exception as e:\n        warnings.warn(f\"Error processing {catalog_file}: {e}\")\n        return None\n</code></pre>"},{"location":"api/request_manager/","title":"Request Manager Module","text":""},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager","title":"<code>RequestManager</code>","text":"Source code in <code>yooink/request/request_manager.py</code> <pre><code>class RequestManager:\n    CACHE_FILE = \"url_cache.json\"\n\n    def __init__(\n            self,\n            api_client: APIClient,\n            use_file_cache: bool = True,\n            cache_expiry: int = 14\n    ) -&gt; None:\n        \"\"\"\n        Initializes the RequestManager with an instance of APIClient and cache\n        options.\n\n        Args:\n            api_client: An instance of the APIClient class.\n            use_file_cache: Whether to enable file-based caching (default\n                False).\n            cache_expiry: The number of days before cache entries expire\n                (default 14 days).\n        \"\"\"\n        self.api_client = api_client\n        self.data_manager = DataManager()\n        self.cached_urls = {}\n        self.use_file_cache = use_file_cache\n        self.cache_expiry = cache_expiry\n\n        # Load cache from file if enabled\n        if self.use_file_cache:\n            self.load_cache_from_file()\n\n    def load_cache_from_file(self) -&gt; None:\n        \"\"\"\n        Loads the cached URLs from a JSON file and removes expired entries.\n        If the file is empty or contains invalid JSON, it initializes an empty\n        cache.\n        \"\"\"\n        if not os.path.exists(self.CACHE_FILE):\n            return\n\n        try:\n            with open(self.CACHE_FILE, 'r') as file:\n                content = file.read().strip()\n\n                if not content:  # Check if file is empty\n                    print(\"Cache file is empty. Initializing new cache.\")\n                    file_cache = {}\n                else:\n                    file_cache = json.loads(content)\n\n            # Filter out expired cache entries\n            current_time = time.time()\n            valid_cache = {\n                key: value for key, value in file_cache.items() if\n                current_time - value['timestamp'] &lt; self.cache_expiry * 86400\n            }\n\n            self.cached_urls = valid_cache\n            self.save_cache_to_file()  # Save the updated cache\n\n        except json.JSONDecodeError:\n            print(\"Cache file contains invalid JSON. Initializing new cache.\")\n            self.cached_urls = {}\n            self.save_cache_to_file()\n\n    def save_cache_to_file(self) -&gt; None:\n        \"\"\"\n        Saves the current cached URLs to a JSON file, appending new URLs to the\n        existing cache.\n        \"\"\"\n        # Load existing cache if it exists\n        file_cache = {}\n        if os.path.exists(self.CACHE_FILE):\n            try:\n                with open(self.CACHE_FILE, 'r') as file:\n                    content = file.read().strip()\n                    if content:\n                        file_cache = json.loads(content)\n            except json.JSONDecodeError:\n                print(\n                    \"Existing cache file contains invalid JSON. \"\n                    \"Overwriting with new cache.\")\n\n        # Merge the in-memory cache with the file cache\n        file_cache.update(self.cached_urls)\n\n        # Write the merged cache to a temporary file, then replace the original\n        # file\n        temp_file = None\n        try:\n            temp_dir = os.path.dirname(self.CACHE_FILE)\n            with tempfile.NamedTemporaryFile('w', dir=temp_dir,\n                                             delete=False) as temp_file:\n                json.dump(file_cache, temp_file)\n\n            # Replace the original cache file with the temp file\n            os.replace(temp_file.name, self.CACHE_FILE)\n\n        except Exception as e:\n            print(f\"Error saving cache: {e}\")\n\n            # Ensure temp file is deleted if something goes wrong\n            if temp_file:\n                os.remove(temp_file.name)\n\n    def list_sites(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Lists all available sites from the API.\n\n        Returns:\n            A list of sites as dictionaries.\n        \"\"\"\n        endpoint = \"\"\n        return self.api_client.make_request(M2MInterface.SENSOR_URL, endpoint)\n\n    def list_nodes(self, site: str) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Lists nodes for a specific site.\n\n        Args:\n            site: The site identifier.\n\n        Returns:\n            List: A list of nodes as dictionaries.\n        \"\"\"\n        endpoint = f\"{site}/\"\n        return self.api_client.make_request(M2MInterface.SENSOR_URL, endpoint)\n\n    def list_sensors(self, site: str, node: str) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Lists sensors for a specific site and node.\n\n        Args:\n            site: The site identifier.\n            node: The node identifier.\n\n        Returns:\n            List: A list of sensors as dictionaries.\n        \"\"\"\n        endpoint = f\"{site}/{node}/\"\n        return self.api_client.make_request(M2MInterface.SENSOR_URL, endpoint)\n\n    def list_methods(\n            self, site: str, node: str, sensor: str) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Lists methods available for a specific data.\n\n        Args:\n            site: The site identifier.\n            node: The node identifier.\n            sensor: The data identifier.\n\n        Returns:\n            A list of methods as dictionaries.\n        \"\"\"\n        endpoint = f\"{site}/{node}/{sensor}/\"\n        return self.api_client.make_request(M2MInterface.SENSOR_URL, endpoint)\n\n    def get_metadata(\n            self, site: str, node: str, sensor: str) -&gt; Dict[str, Any]:\n        \"\"\"\n        Retrieves metadata for a specific data.\n\n        Args:\n            site: The site identifier.\n            node: The node identifier.\n            sensor: The data identifier.\n\n        Returns:\n            The metadata as a dictionary.\n        \"\"\"\n        endpoint = f\"{site}/{node}/{sensor}/metadata\"\n        return self.api_client.make_request(M2MInterface.SENSOR_URL, endpoint)\n\n    def list_streams(\n            self, site: str, node: str, sensor: str, method: str) \\\n            -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Lists available streams for a specific data and method.\n\n        Args:\n            site: The site identifier.\n            node: The node identifier.\n            sensor: The data identifier.\n            method: The method (e.g., telemetered).\n\n        Returns:\n            A list of streams as dictionaries.\n        \"\"\"\n        endpoint = f\"{site}/{node}/{sensor}/{method}/\"\n        return self.api_client.make_request(M2MInterface.SENSOR_URL, endpoint)\n\n    def list_deployments(\n            self, site: str, node: str, sensor: str\n    ) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Lists deployments for a specific site, node, and sensor.\n\n        Args:\n            site: The site identifier.\n            node: The node identifier.\n            sensor: The sensor identifier.\n\n        Returns:\n            A list of deployments as dictionaries.\n        \"\"\"\n        endpoint = f\"{site}/{node}/{sensor}\"\n        return self.api_client.make_request(M2MInterface.DEPLOY_URL, endpoint)\n\n    def get_sensor_information(\n            self, site: str, node: str, sensor: str, deploy: Union[int, str]\n    ) -&gt; list:\n        \"\"\"\n        Retrieves sensor metadata for a specific deployment.\n\n        Args:\n            site: The site identifier.\n            node: The node identifier.\n            sensor: The sensor identifier.\n            deploy: The deployment number.\n\n        Returns:\n            The sensor information as a dictionary.\n        \"\"\"\n        endpoint = f\"{site}/{node}/{sensor}/{str(deploy)}\"\n        return self.api_client.make_request(M2MInterface.DEPLOY_URL, endpoint)\n\n    def get_deployment_dates(\n            self,\n            site: str,\n            node: str,\n            sensor: str,\n            deploy: str | int\n    ) -&gt; Optional[Dict[str, str]]:\n        \"\"\"\n        Retrieves the start and stop dates for a specific deployment.\n\n        Args:\n            site: The site identifier.\n            node: The node identifier.\n            sensor: The sensor identifier.\n            deploy: The deployment number.\n\n        Returns:\n            A dictionary with the start and stop dates, or None if the\n                information is not available.\n        \"\"\"\n        sensor_info = self.get_sensor_information(site, node, sensor,\n                                                  str(deploy))\n\n        if sensor_info:\n            start = time.strftime(\n                '%Y-%m-%dT%H:%M:%S.000Z',\n                time.gmtime(sensor_info[0]['eventStartTime'] / 1000.0))\n\n            if sensor_info[0].get('eventStopTime'):\n                stop = time.strftime(\n                    '%Y-%m-%dT%H:%M:%S.000Z',\n                    time.gmtime(sensor_info[0]['eventStopTime'] / 1000.0))\n            else:\n                stop = time.strftime(\n                    '%Y-%m-%dT%H:%M:%S.000Z',\n                    time.gmtime(time.time()))\n\n            return {'start': start, 'stop': stop}\n        else:\n            return None\n\n    def get_sensor_history(self, uid: str) -&gt; Dict[str, Any]:\n        \"\"\"\n        Retrieves the asset and calibration information for a sensor across all\n        deployments.\n\n        Args:\n            uid: The unique asset identifier (UID).\n\n        Returns:\n            The sensor history as a dictionary.\n        \"\"\"\n        endpoint = f\"asset/deployments/{uid}?editphase=ALL\"\n        return self.api_client.make_request(M2MInterface.DEPLOY_URL, endpoint)\n\n    def fetch_data(\n            self, site: str, node: str, sensor: str, method: str,\n            stream: str, begin_datetime: str, end_datetime: str,\n            use_dask=False, tag: str = r'.*\\.nc$') -&gt; Dataset | None:\n        \"\"\"\n        Fetch the URLs for netCDF files from the THREDDS server based on site,\n        node, data, and method.\n        \"\"\"\n        # Construct a cache key using relevant details\n        cache_key = (f\"{site}_{node}_{sensor}_{method}_{stream}_\"\n                     f\"{begin_datetime}_{end_datetime}\")\n\n        # Check if the request is already cached\n        if cache_key in self.cached_urls:\n            print(f\"Using cached URL for request: {cache_key}\")\n            async_url = self.cached_urls[cache_key]['async_url']\n            tds_url = self.cached_urls[cache_key]['tds_url']\n            # You can now re-check the status of this request\n            check_complete = async_url + '/status.txt'\n            response = self.api_client.session.get(check_complete)\n            if response.status_code == requests.codes.ok:\n                datasets = self.get_filtered_files(\n                    {'allURLs': [tds_url]}, tag)\n            else:\n                print(f\"Data not ready yet for cached request: {cache_key}\")\n                return None\n        else:\n            # Proceed with normal request flow if not cached\n            print(\n                f\"Requesting data for site: {site}, node: {node}, \"\n                f\"sensor: {sensor}, method: {method}, stream: {stream}\")\n            data = self.wait_for_m2m_data(site, node, sensor, method, stream,\n                                          begin_datetime, end_datetime)\n            if not data:\n                print(\"Request failed or timed out. Please try again later.\")\n                return None\n\n            # Extract URLs from the M2M response\n            datasets = self.get_filtered_files(data)\n\n        # Continue with processing and merging the datasets as before\n        if len(datasets) &gt; 5:\n            part_files = partial(self.data_manager.process_file,\n                                 use_dask=use_dask)\n            with ProcessPoolExecutor(max_workers=4) as executor:\n                frames = list(tqdm(executor.map(part_files, datasets),\n                                   total=len(datasets),\n                                   desc='Processing files'))\n        else:\n            frames = [self.data_manager.process_file(f, use_dask=use_dask)\n                      for f in\n                      tqdm(datasets, desc='Processing files')]\n\n        return self.data_manager.merge_frames(frames)\n\n    def wait_for_m2m_data(\n            self, site: str, node: str, sensor: str, method: str,\n            stream: str, begin_datetime: str, end_datetime: str) -&gt; Any | None:\n        \"\"\"\n        Request data from the M2M API and wait for completion, displaying\n        progress with tqdm.\n        \"\"\"\n        # Step 1: Set up request details\n        params = {\n            'beginDT': begin_datetime, 'endDT': end_datetime,\n            'format': 'application/netcdf', 'include_provenance': 'true',\n            'include_annotations': 'true'}\n        details = f\"{site}/{node}/{sensor}/{method}/{stream}\"\n\n        # Step 2: Make the request and get the response\n        response = self.api_client.make_request(M2MInterface.SENSOR_URL,\n                                                details, params)\n\n        if 'allURLs' not in response:\n            print(\"No URLs found in the response.\")\n            return None\n\n        # Step 3: Extract the async URL and status URL\n        url = [url for url in response['allURLs'] if\n               re.match(r'.*async_results.*', url)][0]\n        thredds_url = response['allURLs'][0]\n        check_complete = url + '/status.txt'\n\n        # Step 4: Cache the URL immediately after the request is submitted\n        cache_key = (f\"{site}_{node}_{sensor}_{method}_{stream}_\"\n                     f\"{begin_datetime}_{end_datetime}\")\n        self.cached_urls[cache_key] = {\n            'tds_url': thredds_url,\n            'async_url': url,\n            'timestamp': time.time()\n        }\n\n        if self.use_file_cache:\n            self.save_cache_to_file()  # Save cache immediately\n\n        # Step 5: Use tqdm to wait for completion\n        print(\n            \"Waiting for OOINet to process and prepare the data. This may \"\n            \"take up to 20 minutes.\")\n        with tqdm(total=400, desc='Waiting', file=sys.stdout) as bar:\n            for i in range(400):\n                try:\n                    r = self.api_client.session.get(check_complete,\n                                                    timeout=(3.05, 120))\n                    if r.status_code == 200:  # Data is ready\n                        bar.n = 400  # Complete the progress bar\n                        return response\n                    elif r.status_code == 404:\n                        pass\n                except requests.exceptions.RequestException as e:\n                    print(f\"Error during status check: {e}\")\n\n                bar.update()\n                bar.refresh()\n                time.sleep(3)  # Wait 3 seconds between checks\n\n        # If we exit the loop without the request being ready, return None\n        print(\"Data request timed out. Please try again later.\")\n        return None\n\n    def get_filtered_files(\n            self,\n            data: dict,\n            tag: str = r'.*\\.nc$'\n    ) -&gt; List[str]:\n        \"\"\"\n        Extract the relevant file URLs from the M2M response, filtered using a\n        regex tag.\n\n        Args:\n            data: JSON response from the M2M API request.\n            tag: A regex tag to filter the .nc files (default is to match any\n                .nc file).\n\n        Returns:\n            A list of filtered .nc file URLs.\n        \"\"\"\n        # Fetch the datasets page from the THREDDS server\n        datasets_page = self.api_client.fetch_thredds_page(data['allURLs'][0])\n\n        # Use the list_files function with regex to filter the files\n        return self.list_files(datasets_page, tag=tag)\n\n    @staticmethod\n    def list_files(\n            page_content: str,\n            tag: str = r'.*\\.nc$'\n    ) -&gt; List[str]:\n        \"\"\"\n        Create a list of the NetCDF data files in the THREDDS catalog using\n        regex.\n\n        Args:\n            page_content: HTML content of the THREDDS catalog page.\n            tag: A regex pattern to filter files.\n\n        Returns:\n            A list of files that match the regex tag.\n        \"\"\"\n        pattern = re.compile(tag)\n        soup = BeautifulSoup(page_content, 'html.parser')\n        return [node.get('href') for node in\n                soup.find_all('a', string=pattern)]\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.__init__","title":"<code>__init__(api_client, use_file_cache=True, cache_expiry=14)</code>","text":"<p>Initializes the RequestManager with an instance of APIClient and cache options.</p> <p>Parameters:</p> Name Type Description Default <code>api_client</code> <code>APIClient</code> <p>An instance of the APIClient class.</p> required <code>use_file_cache</code> <code>bool</code> <p>Whether to enable file-based caching (default False).</p> <code>True</code> <code>cache_expiry</code> <code>int</code> <p>The number of days before cache entries expire (default 14 days).</p> <code>14</code> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def __init__(\n        self,\n        api_client: APIClient,\n        use_file_cache: bool = True,\n        cache_expiry: int = 14\n) -&gt; None:\n    \"\"\"\n    Initializes the RequestManager with an instance of APIClient and cache\n    options.\n\n    Args:\n        api_client: An instance of the APIClient class.\n        use_file_cache: Whether to enable file-based caching (default\n            False).\n        cache_expiry: The number of days before cache entries expire\n            (default 14 days).\n    \"\"\"\n    self.api_client = api_client\n    self.data_manager = DataManager()\n    self.cached_urls = {}\n    self.use_file_cache = use_file_cache\n    self.cache_expiry = cache_expiry\n\n    # Load cache from file if enabled\n    if self.use_file_cache:\n        self.load_cache_from_file()\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.fetch_data","title":"<code>fetch_data(site, node, sensor, method, stream, begin_datetime, end_datetime, use_dask=False, tag='.*\\\\.nc$')</code>","text":"<p>Fetch the URLs for netCDF files from the THREDDS server based on site, node, data, and method.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def fetch_data(\n        self, site: str, node: str, sensor: str, method: str,\n        stream: str, begin_datetime: str, end_datetime: str,\n        use_dask=False, tag: str = r'.*\\.nc$') -&gt; Dataset | None:\n    \"\"\"\n    Fetch the URLs for netCDF files from the THREDDS server based on site,\n    node, data, and method.\n    \"\"\"\n    # Construct a cache key using relevant details\n    cache_key = (f\"{site}_{node}_{sensor}_{method}_{stream}_\"\n                 f\"{begin_datetime}_{end_datetime}\")\n\n    # Check if the request is already cached\n    if cache_key in self.cached_urls:\n        print(f\"Using cached URL for request: {cache_key}\")\n        async_url = self.cached_urls[cache_key]['async_url']\n        tds_url = self.cached_urls[cache_key]['tds_url']\n        # You can now re-check the status of this request\n        check_complete = async_url + '/status.txt'\n        response = self.api_client.session.get(check_complete)\n        if response.status_code == requests.codes.ok:\n            datasets = self.get_filtered_files(\n                {'allURLs': [tds_url]}, tag)\n        else:\n            print(f\"Data not ready yet for cached request: {cache_key}\")\n            return None\n    else:\n        # Proceed with normal request flow if not cached\n        print(\n            f\"Requesting data for site: {site}, node: {node}, \"\n            f\"sensor: {sensor}, method: {method}, stream: {stream}\")\n        data = self.wait_for_m2m_data(site, node, sensor, method, stream,\n                                      begin_datetime, end_datetime)\n        if not data:\n            print(\"Request failed or timed out. Please try again later.\")\n            return None\n\n        # Extract URLs from the M2M response\n        datasets = self.get_filtered_files(data)\n\n    # Continue with processing and merging the datasets as before\n    if len(datasets) &gt; 5:\n        part_files = partial(self.data_manager.process_file,\n                             use_dask=use_dask)\n        with ProcessPoolExecutor(max_workers=4) as executor:\n            frames = list(tqdm(executor.map(part_files, datasets),\n                               total=len(datasets),\n                               desc='Processing files'))\n    else:\n        frames = [self.data_manager.process_file(f, use_dask=use_dask)\n                  for f in\n                  tqdm(datasets, desc='Processing files')]\n\n    return self.data_manager.merge_frames(frames)\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.get_deployment_dates","title":"<code>get_deployment_dates(site, node, sensor, deploy)</code>","text":"<p>Retrieves the start and stop dates for a specific deployment.</p> <p>Parameters:</p> Name Type Description Default <code>site</code> <code>str</code> <p>The site identifier.</p> required <code>node</code> <code>str</code> <p>The node identifier.</p> required <code>sensor</code> <code>str</code> <p>The sensor identifier.</p> required <code>deploy</code> <code>str | int</code> <p>The deployment number.</p> required <p>Returns:</p> Type Description <code>Optional[Dict[str, str]]</code> <p>A dictionary with the start and stop dates, or None if the information is not available.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def get_deployment_dates(\n        self,\n        site: str,\n        node: str,\n        sensor: str,\n        deploy: str | int\n) -&gt; Optional[Dict[str, str]]:\n    \"\"\"\n    Retrieves the start and stop dates for a specific deployment.\n\n    Args:\n        site: The site identifier.\n        node: The node identifier.\n        sensor: The sensor identifier.\n        deploy: The deployment number.\n\n    Returns:\n        A dictionary with the start and stop dates, or None if the\n            information is not available.\n    \"\"\"\n    sensor_info = self.get_sensor_information(site, node, sensor,\n                                              str(deploy))\n\n    if sensor_info:\n        start = time.strftime(\n            '%Y-%m-%dT%H:%M:%S.000Z',\n            time.gmtime(sensor_info[0]['eventStartTime'] / 1000.0))\n\n        if sensor_info[0].get('eventStopTime'):\n            stop = time.strftime(\n                '%Y-%m-%dT%H:%M:%S.000Z',\n                time.gmtime(sensor_info[0]['eventStopTime'] / 1000.0))\n        else:\n            stop = time.strftime(\n                '%Y-%m-%dT%H:%M:%S.000Z',\n                time.gmtime(time.time()))\n\n        return {'start': start, 'stop': stop}\n    else:\n        return None\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.get_filtered_files","title":"<code>get_filtered_files(data, tag='.*\\\\.nc$')</code>","text":"<p>Extract the relevant file URLs from the M2M response, filtered using a regex tag.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>JSON response from the M2M API request.</p> required <code>tag</code> <code>str</code> <p>A regex tag to filter the .nc files (default is to match any .nc file).</p> <code>'.*\\\\.nc$'</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of filtered .nc file URLs.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def get_filtered_files(\n        self,\n        data: dict,\n        tag: str = r'.*\\.nc$'\n) -&gt; List[str]:\n    \"\"\"\n    Extract the relevant file URLs from the M2M response, filtered using a\n    regex tag.\n\n    Args:\n        data: JSON response from the M2M API request.\n        tag: A regex tag to filter the .nc files (default is to match any\n            .nc file).\n\n    Returns:\n        A list of filtered .nc file URLs.\n    \"\"\"\n    # Fetch the datasets page from the THREDDS server\n    datasets_page = self.api_client.fetch_thredds_page(data['allURLs'][0])\n\n    # Use the list_files function with regex to filter the files\n    return self.list_files(datasets_page, tag=tag)\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.get_metadata","title":"<code>get_metadata(site, node, sensor)</code>","text":"<p>Retrieves metadata for a specific data.</p> <p>Parameters:</p> Name Type Description Default <code>site</code> <code>str</code> <p>The site identifier.</p> required <code>node</code> <code>str</code> <p>The node identifier.</p> required <code>sensor</code> <code>str</code> <p>The data identifier.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The metadata as a dictionary.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def get_metadata(\n        self, site: str, node: str, sensor: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    Retrieves metadata for a specific data.\n\n    Args:\n        site: The site identifier.\n        node: The node identifier.\n        sensor: The data identifier.\n\n    Returns:\n        The metadata as a dictionary.\n    \"\"\"\n    endpoint = f\"{site}/{node}/{sensor}/metadata\"\n    return self.api_client.make_request(M2MInterface.SENSOR_URL, endpoint)\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.get_sensor_history","title":"<code>get_sensor_history(uid)</code>","text":"<p>Retrieves the asset and calibration information for a sensor across all deployments.</p> <p>Parameters:</p> Name Type Description Default <code>uid</code> <code>str</code> <p>The unique asset identifier (UID).</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>The sensor history as a dictionary.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def get_sensor_history(self, uid: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    Retrieves the asset and calibration information for a sensor across all\n    deployments.\n\n    Args:\n        uid: The unique asset identifier (UID).\n\n    Returns:\n        The sensor history as a dictionary.\n    \"\"\"\n    endpoint = f\"asset/deployments/{uid}?editphase=ALL\"\n    return self.api_client.make_request(M2MInterface.DEPLOY_URL, endpoint)\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.get_sensor_information","title":"<code>get_sensor_information(site, node, sensor, deploy)</code>","text":"<p>Retrieves sensor metadata for a specific deployment.</p> <p>Parameters:</p> Name Type Description Default <code>site</code> <code>str</code> <p>The site identifier.</p> required <code>node</code> <code>str</code> <p>The node identifier.</p> required <code>sensor</code> <code>str</code> <p>The sensor identifier.</p> required <code>deploy</code> <code>Union[int, str]</code> <p>The deployment number.</p> required <p>Returns:</p> Type Description <code>list</code> <p>The sensor information as a dictionary.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def get_sensor_information(\n        self, site: str, node: str, sensor: str, deploy: Union[int, str]\n) -&gt; list:\n    \"\"\"\n    Retrieves sensor metadata for a specific deployment.\n\n    Args:\n        site: The site identifier.\n        node: The node identifier.\n        sensor: The sensor identifier.\n        deploy: The deployment number.\n\n    Returns:\n        The sensor information as a dictionary.\n    \"\"\"\n    endpoint = f\"{site}/{node}/{sensor}/{str(deploy)}\"\n    return self.api_client.make_request(M2MInterface.DEPLOY_URL, endpoint)\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.list_deployments","title":"<code>list_deployments(site, node, sensor)</code>","text":"<p>Lists deployments for a specific site, node, and sensor.</p> <p>Parameters:</p> Name Type Description Default <code>site</code> <code>str</code> <p>The site identifier.</p> required <code>node</code> <code>str</code> <p>The node identifier.</p> required <code>sensor</code> <code>str</code> <p>The sensor identifier.</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>A list of deployments as dictionaries.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def list_deployments(\n        self, site: str, node: str, sensor: str\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Lists deployments for a specific site, node, and sensor.\n\n    Args:\n        site: The site identifier.\n        node: The node identifier.\n        sensor: The sensor identifier.\n\n    Returns:\n        A list of deployments as dictionaries.\n    \"\"\"\n    endpoint = f\"{site}/{node}/{sensor}\"\n    return self.api_client.make_request(M2MInterface.DEPLOY_URL, endpoint)\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.list_files","title":"<code>list_files(page_content, tag='.*\\\\.nc$')</code>  <code>staticmethod</code>","text":"<p>Create a list of the NetCDF data files in the THREDDS catalog using regex.</p> <p>Parameters:</p> Name Type Description Default <code>page_content</code> <code>str</code> <p>HTML content of the THREDDS catalog page.</p> required <code>tag</code> <code>str</code> <p>A regex pattern to filter files.</p> <code>'.*\\\\.nc$'</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of files that match the regex tag.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>@staticmethod\ndef list_files(\n        page_content: str,\n        tag: str = r'.*\\.nc$'\n) -&gt; List[str]:\n    \"\"\"\n    Create a list of the NetCDF data files in the THREDDS catalog using\n    regex.\n\n    Args:\n        page_content: HTML content of the THREDDS catalog page.\n        tag: A regex pattern to filter files.\n\n    Returns:\n        A list of files that match the regex tag.\n    \"\"\"\n    pattern = re.compile(tag)\n    soup = BeautifulSoup(page_content, 'html.parser')\n    return [node.get('href') for node in\n            soup.find_all('a', string=pattern)]\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.list_methods","title":"<code>list_methods(site, node, sensor)</code>","text":"<p>Lists methods available for a specific data.</p> <p>Parameters:</p> Name Type Description Default <code>site</code> <code>str</code> <p>The site identifier.</p> required <code>node</code> <code>str</code> <p>The node identifier.</p> required <code>sensor</code> <code>str</code> <p>The data identifier.</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>A list of methods as dictionaries.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def list_methods(\n        self, site: str, node: str, sensor: str) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Lists methods available for a specific data.\n\n    Args:\n        site: The site identifier.\n        node: The node identifier.\n        sensor: The data identifier.\n\n    Returns:\n        A list of methods as dictionaries.\n    \"\"\"\n    endpoint = f\"{site}/{node}/{sensor}/\"\n    return self.api_client.make_request(M2MInterface.SENSOR_URL, endpoint)\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.list_nodes","title":"<code>list_nodes(site)</code>","text":"<p>Lists nodes for a specific site.</p> <p>Parameters:</p> Name Type Description Default <code>site</code> <code>str</code> <p>The site identifier.</p> required <p>Returns:</p> Name Type Description <code>List</code> <code>List[Dict[str, Any]]</code> <p>A list of nodes as dictionaries.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def list_nodes(self, site: str) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Lists nodes for a specific site.\n\n    Args:\n        site: The site identifier.\n\n    Returns:\n        List: A list of nodes as dictionaries.\n    \"\"\"\n    endpoint = f\"{site}/\"\n    return self.api_client.make_request(M2MInterface.SENSOR_URL, endpoint)\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.list_sensors","title":"<code>list_sensors(site, node)</code>","text":"<p>Lists sensors for a specific site and node.</p> <p>Parameters:</p> Name Type Description Default <code>site</code> <code>str</code> <p>The site identifier.</p> required <code>node</code> <code>str</code> <p>The node identifier.</p> required <p>Returns:</p> Name Type Description <code>List</code> <code>List[Dict[str, Any]]</code> <p>A list of sensors as dictionaries.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def list_sensors(self, site: str, node: str) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Lists sensors for a specific site and node.\n\n    Args:\n        site: The site identifier.\n        node: The node identifier.\n\n    Returns:\n        List: A list of sensors as dictionaries.\n    \"\"\"\n    endpoint = f\"{site}/{node}/\"\n    return self.api_client.make_request(M2MInterface.SENSOR_URL, endpoint)\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.list_sites","title":"<code>list_sites()</code>","text":"<p>Lists all available sites from the API.</p> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>A list of sites as dictionaries.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def list_sites(self) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Lists all available sites from the API.\n\n    Returns:\n        A list of sites as dictionaries.\n    \"\"\"\n    endpoint = \"\"\n    return self.api_client.make_request(M2MInterface.SENSOR_URL, endpoint)\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.list_streams","title":"<code>list_streams(site, node, sensor, method)</code>","text":"<p>Lists available streams for a specific data and method.</p> <p>Parameters:</p> Name Type Description Default <code>site</code> <code>str</code> <p>The site identifier.</p> required <code>node</code> <code>str</code> <p>The node identifier.</p> required <code>sensor</code> <code>str</code> <p>The data identifier.</p> required <code>method</code> <code>str</code> <p>The method (e.g., telemetered).</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>A list of streams as dictionaries.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def list_streams(\n        self, site: str, node: str, sensor: str, method: str) \\\n        -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Lists available streams for a specific data and method.\n\n    Args:\n        site: The site identifier.\n        node: The node identifier.\n        sensor: The data identifier.\n        method: The method (e.g., telemetered).\n\n    Returns:\n        A list of streams as dictionaries.\n    \"\"\"\n    endpoint = f\"{site}/{node}/{sensor}/{method}/\"\n    return self.api_client.make_request(M2MInterface.SENSOR_URL, endpoint)\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.load_cache_from_file","title":"<code>load_cache_from_file()</code>","text":"<p>Loads the cached URLs from a JSON file and removes expired entries. If the file is empty or contains invalid JSON, it initializes an empty cache.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def load_cache_from_file(self) -&gt; None:\n    \"\"\"\n    Loads the cached URLs from a JSON file and removes expired entries.\n    If the file is empty or contains invalid JSON, it initializes an empty\n    cache.\n    \"\"\"\n    if not os.path.exists(self.CACHE_FILE):\n        return\n\n    try:\n        with open(self.CACHE_FILE, 'r') as file:\n            content = file.read().strip()\n\n            if not content:  # Check if file is empty\n                print(\"Cache file is empty. Initializing new cache.\")\n                file_cache = {}\n            else:\n                file_cache = json.loads(content)\n\n        # Filter out expired cache entries\n        current_time = time.time()\n        valid_cache = {\n            key: value for key, value in file_cache.items() if\n            current_time - value['timestamp'] &lt; self.cache_expiry * 86400\n        }\n\n        self.cached_urls = valid_cache\n        self.save_cache_to_file()  # Save the updated cache\n\n    except json.JSONDecodeError:\n        print(\"Cache file contains invalid JSON. Initializing new cache.\")\n        self.cached_urls = {}\n        self.save_cache_to_file()\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.save_cache_to_file","title":"<code>save_cache_to_file()</code>","text":"<p>Saves the current cached URLs to a JSON file, appending new URLs to the existing cache.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def save_cache_to_file(self) -&gt; None:\n    \"\"\"\n    Saves the current cached URLs to a JSON file, appending new URLs to the\n    existing cache.\n    \"\"\"\n    # Load existing cache if it exists\n    file_cache = {}\n    if os.path.exists(self.CACHE_FILE):\n        try:\n            with open(self.CACHE_FILE, 'r') as file:\n                content = file.read().strip()\n                if content:\n                    file_cache = json.loads(content)\n        except json.JSONDecodeError:\n            print(\n                \"Existing cache file contains invalid JSON. \"\n                \"Overwriting with new cache.\")\n\n    # Merge the in-memory cache with the file cache\n    file_cache.update(self.cached_urls)\n\n    # Write the merged cache to a temporary file, then replace the original\n    # file\n    temp_file = None\n    try:\n        temp_dir = os.path.dirname(self.CACHE_FILE)\n        with tempfile.NamedTemporaryFile('w', dir=temp_dir,\n                                         delete=False) as temp_file:\n            json.dump(file_cache, temp_file)\n\n        # Replace the original cache file with the temp file\n        os.replace(temp_file.name, self.CACHE_FILE)\n\n    except Exception as e:\n        print(f\"Error saving cache: {e}\")\n\n        # Ensure temp file is deleted if something goes wrong\n        if temp_file:\n            os.remove(temp_file.name)\n</code></pre>"},{"location":"api/request_manager/#yooink.request.request_manager.RequestManager.wait_for_m2m_data","title":"<code>wait_for_m2m_data(site, node, sensor, method, stream, begin_datetime, end_datetime)</code>","text":"<p>Request data from the M2M API and wait for completion, displaying progress with tqdm.</p> Source code in <code>yooink/request/request_manager.py</code> <pre><code>def wait_for_m2m_data(\n        self, site: str, node: str, sensor: str, method: str,\n        stream: str, begin_datetime: str, end_datetime: str) -&gt; Any | None:\n    \"\"\"\n    Request data from the M2M API and wait for completion, displaying\n    progress with tqdm.\n    \"\"\"\n    # Step 1: Set up request details\n    params = {\n        'beginDT': begin_datetime, 'endDT': end_datetime,\n        'format': 'application/netcdf', 'include_provenance': 'true',\n        'include_annotations': 'true'}\n    details = f\"{site}/{node}/{sensor}/{method}/{stream}\"\n\n    # Step 2: Make the request and get the response\n    response = self.api_client.make_request(M2MInterface.SENSOR_URL,\n                                            details, params)\n\n    if 'allURLs' not in response:\n        print(\"No URLs found in the response.\")\n        return None\n\n    # Step 3: Extract the async URL and status URL\n    url = [url for url in response['allURLs'] if\n           re.match(r'.*async_results.*', url)][0]\n    thredds_url = response['allURLs'][0]\n    check_complete = url + '/status.txt'\n\n    # Step 4: Cache the URL immediately after the request is submitted\n    cache_key = (f\"{site}_{node}_{sensor}_{method}_{stream}_\"\n                 f\"{begin_datetime}_{end_datetime}\")\n    self.cached_urls[cache_key] = {\n        'tds_url': thredds_url,\n        'async_url': url,\n        'timestamp': time.time()\n    }\n\n    if self.use_file_cache:\n        self.save_cache_to_file()  # Save cache immediately\n\n    # Step 5: Use tqdm to wait for completion\n    print(\n        \"Waiting for OOINet to process and prepare the data. This may \"\n        \"take up to 20 minutes.\")\n    with tqdm(total=400, desc='Waiting', file=sys.stdout) as bar:\n        for i in range(400):\n            try:\n                r = self.api_client.session.get(check_complete,\n                                                timeout=(3.05, 120))\n                if r.status_code == 200:  # Data is ready\n                    bar.n = 400  # Complete the progress bar\n                    return response\n                elif r.status_code == 404:\n                    pass\n            except requests.exceptions.RequestException as e:\n                print(f\"Error during status check: {e}\")\n\n            bar.update()\n            bar.refresh()\n            time.sleep(3)  # Wait 3 seconds between checks\n\n    # If we exit the loop without the request being ready, return None\n    print(\"Data request timed out. Please try again later.\")\n    return None\n</code></pre>"},{"location":"quick_start/","title":"Quick Start","text":"<p>In this section, we will walk through a few short examples that you can  work through yourself to get a feel for how to use the yooink package. </p> <ul> <li>Setting up API access</li> <li>Data overview</li> </ul>"},{"location":"quick_start/api_setup/","title":"API access","text":"<p>To get OOI API access, you'll need a username and token.</p> <ol> <li>Create a user account on ooinet.oceanobservatories.org (you can also use an existing CILogin or Google account.</li> <li>Log in</li> <li>Navigate to the drop down menu screen in the top-right corner menu</li> <li>Click on the \u201cUser Profile\u201d element of the drop down</li> <li>Scroll to the bottom to see your API Username and API Token</li> </ol>"},{"location":"quick_start/api_setup/#api-token-security","title":"API token security","text":"<p>You'll notice that down below you need to provide an API key and token.  Those definitely shouldn't be hard coded into a file that lives on a public  (or really even private) repository. An easy way to handle that is to  store your API key and token as local environment variables and then use the  os library to access the contents of the environment variable.</p> <p>To save that environment variable using macOS or Linux terminal, use:</p> <p><code>export OOI_USER=abc123</code> </p> <p>On Windows, you'd use:</p> <p><code>setx OOI_TOKEN \"abc123\"</code></p> <p>You can access those environment variables in Python using:</p> <pre><code>import os\n\napi_username = os.getenv('OOI_USER')\n</code></pre> <p>Other options</p> <ul> <li>Save environment variables more permanently on your local computer. We won't go into detail here but you can find lots of simple instructions if you do a quick google search.</li> <li>Hard-code those values right into the script. Just be careful not to upload!</li> </ul>"},{"location":"quick_start/data_overview/","title":"Data Overview","text":"<p>This map shows a curated subset of the most-used OOI instruments from  the Coastal Endurance and Axial Seamount arrays. Note that this is only the  data available via the M2M interface so it does not include more complex  data streams like acoustic/seismic and camera/video data. </p> <p>Just below the map is a search bar and a table. You can use the search bar  to narrow down the subset of instruments displayed in the table. Each row  of the table has a checkbox on the left-most side of the row. You can click  one or more of those to highlight specific instruments on the map. </p> <p>You can pan and zoom on this map and you can  also click on the points to get some information about the instrument. </p>"},{"location":"quick_start/simple_data_query/","title":"Simple Data Query","text":"<p>... coming soon! :-) </p>"}]}